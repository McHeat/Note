# Using nginx as HTTP load balancer

- Load balancing methods
- Default load balancing configuration
- Least connected load balancing
- Session persistence
- Weighted load balancing
- Health checks
- Further reading


##   Introduction

Load balancing across multiple application instances is a commonly used technique for optimizing resource utilization, maximizing throughput, reducing latency, and ensuring fault-tolerant configurations.

跨多程序实例负载平衡是一种通用技术，主要用于优化资源利用率、最大化吞吐量、减少延迟、以及确保容错配置。

It is possible to use nginx as a very efficient HTTP load balancer to distribute traffic to several application servers and to improve performance, scalability and reliability of web applications with nginx.

可以使用nginx作为高效的HTTP负载平衡器，将流量分配到多个应用程序服务器以改善nginx下web程序的性能、可扩展性以及可靠性。

##     Load balancing methods

The following load balancing mechanisms (or methods) are supported in nginx:

nginx平台支持下述负载平衡机制（或方法）：

- round-robin — requests to the application servers are distributed in a round-robin fashion,

- least-connected — next request is assigned to the server with the least number of active connections,
- ip-hash — a hash-function is used to determine what server should be selected for the next request (based on the client’s IP address).

- 循环--对程序服务器的请求以循环方式进行分配
- 最少链接--下一请求被分配给服务器，其具有最少的活动链接数
- IP-hash--hash功能被用于决定应该为下一请求选择哪种服务器（基于客户端的IP地址）。



##Default load balancing configuration

The simplest configuration for load balancing with nginx may look like the following:

nginx下负载平衡的最简单的配置如下：

	http {
    	upstream myapp1 {
        	server srv1.example.com;
        	server srv2.example.com;
        	server srv3.example.com;
    	}

    	server {
        	listen 80;

        	location / {
            	proxy_pass http://myapp1;
        	}
    	}
	}

In the example above, there are 3 instances of the same application running on srv1-srv3. When the load balancing method is not specifically configured, it defaults to round-robin. All requests are [proxied](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass) to the server group myapp1, and nginx applies HTTP load balancing to distribute the requests.

在上例中，在同一个程序中有3个实例运行在srv1-srv3下。当负载平衡法不能明确配置时，默认进行循环。所有请求都被代理[proxied](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass)到服务器群myapp1，且nginx应用HTTP负载平衡进行请求分配。

Reverse proxy implementation in nginx includes load balancing for HTTP, HTTPS, FastCGI, uwsgi, SCGI, memcached, and gRPC.

nginx中反向代理的实现包括HTTP负载平衡、HTTPS、FastCGI、 uwsgi、 SCGI、 memcached以及gRPC.

To configure load balancing for HTTPS instead of HTTP, just use “https” as the protocol.

配置HTTPS的负载平衡来代替HTTP，只需要使用“https”作为协议即可。

When setting up load balancing for FastCGI, uwsgi, SCGI, memcached, or gRPC, use [fastcgi_pass](http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_pass), [uwsgi_pass](http://nginx.org/en/docs/http/ngx_http_uwsgi_module.html#uwsgi_pass), [scgi_pass](http://nginx.org/en/docs/http/ngx_http_scgi_module.html#scgi_pass), [memcached_pass](http://nginx.org/en/docs/http/ngx_http_memcached_module.html#memcached_pass), and [grpc_pass](http://nginx.org/en/docs/http/ngx_http_grpc_module.html#grpc_pass) directives respectively.

当为FastCGI设置负载平衡时使用[fastcgi_pass](http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_pass)指令，为uwsgi设置负载平衡时使用[uwsgi_pass](http://nginx.org/en/docs/http/ngx_http_uwsgi_module.html#uwsgi_pass)指令, 为SCGI设置负载平衡时使用[scgi_pass](http://nginx.org/en/docs/http/ngx_http_scgi_module.html#scgi_pass)指令, 为memcached设置负载平衡时使用[memcached_pass](http://nginx.org/en/docs/http/ngx_http_memcached_module.html#memcached_pass)指令，为gRPC设置负载平衡时使用[grpc_pass](http://nginx.org/en/docs/http/ngx_http_grpc_module.html#grpc_pass)指令。

## Least connected load balancing

Another load balancing discipline is least-connected. Least-connected allows controlling the load on application instances more fairly in a situation when some of the requests take longer to complete.

另一种负载平衡规则是最少连接Least-connected。当一些请求需要更多时间完成时，Least-connected允许在程序实例中更加公平的进行负载控制。

With the least-connected load balancing, nginx will try not to overload a busy application server with excessive requests, distributing the new requests to a less busy server instead.

使用least-connected load balancing时，nginx不会将过多请求加载到繁忙的程序服务器上，而是将新请求分配到较为不繁忙的服务器上。

least-connected load balancing in nginx is activated when the [least_conn](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#least_conn) directive is used as part of the server group configuration:

在nginx下，当使用[least_conn](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#least_conn)指令作为服务群配置的一部分时，可激活least-connected load balancing：

    upstream myapp1 {
        least_conn;
        server srv1.example.com;
        server srv2.example.com;
        server srv3.example.com;
    }



##        Session persistence

Please note that with round-robin or least-connected load balancing, each subsequent client’s request can be potentially distributed to a different server. There is no guarantee that the same client will be always directed to the same server.

请注意使用循环round-robin或least-connected load balancing时，每个后续客户端的请求都有潜在可能分配给不同的服务器。不能保证同一个客户端始终会指向同一个服务器。

If there is the need to tie a client to a particular application server — in other words, make the client’s session “sticky” or “persistent” in terms of always trying to select a particular server — the ip-hash load balancing mechanism can be used.

如果不需要将一个客户端与一个特定的程序服务器联系在一起——换句话说，使客户端的会话“粘附”或“持久”以总是尝试去选择特定服务器——— 可是使用ip-hash负载平衡机制。

With ip-hash, the client’s IP address is used as a hashing key to determine what server in a server group should be selected for the client’s requests. This method ensures that the requests from the same client will always be directed to the same server except when this server is unavailable.

使用ip-hash时，客户端的IP地址会作为hashing 关键字用于决定在服务器群里应该为客户端请求选择什么服务器。这种方法确保来自同一个客户端的请求会总是指向同一个服务器，除非服务器不可用。

To configure ip-hash load balancing, just add the [ip_hash](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#ip_hash) directive to the server (upstream) group configuration:

配置ip-hash 负载平衡，只需要在服务器（上游）群配置中添加[ip_hash](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#ip_hash)指令：

	upstream myapp1 {
    	ip_hash;
    	server srv1.example.com;
    	server srv2.example.com;
    	server srv3.example.com;
	}


##      Weighted load balancing

It is also possible to influence nginx load balancing algorithms even further by using server weights.

使用服务器权重也可以进一步影响nginx负载平衡算法。

In the examples above, the server weights are not configured which means that all specified servers are treated as equally qualified for a particular load balancing method.

在上述例子中，没有配置服务器权重意味着所有明确的服务器都被当做都可以适用特定的负载平衡方法。

With the round-robin in particular it also means a more or less equal distribution of requests across the servers — provided there are enough requests, and when the requests are processed in a uniform manner and completed fast enough.

特别是round-robin，它意味着在服务器上请求或多或少或相等的分布——假如有足够的请求并且当请求使用统一方式进行处理且完成的足够快。

When the [weight](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server) parameter is specified for a server, the weight is accounted as part of the load balancing decision.

当为服务器指定权重[weight](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server)参数时，权重被认为是负载平衡决策的一部分。

    upstream myapp1 {
        server srv1.example.com weight=3;
        server srv2.example.com;
        server srv3.example.com;
    }


With this configuration, every 5 new requests will be distributed across the application instances as the following: 3 requests will be directed to srv1, one request will go to srv2, and another one — to srv3.

使用这种配置，每5个新请求将会被分配到程序实例中，如下分布：3个请求将会被指向srv1，一个请求指向srv2，一个请求指向srv3。

It is similarly possible to use weights with the least-connected and ip-hash load balancing in the recent versions of nginx.

在最新版本的nginx中，使用最少连接及ip-hash的权重是可以的。

##     Health checks

Reverse proxy implementation in nginx includes in-band (or passive) server health checks. If the response from a particular server fails with an error, nginx will mark this server as failed, and will try to avoid selecting this server for subsequent inbound requests for a while.

nginx中反向代理的实现包括in-band带内（或消极）服务器健康检查。如果来自特定服务器的响应因错误而失败，nginx会标记该服务器为失败，且会在一定时间内尽量避免选择该服务器进行后续inbound请求。

The [max_fails](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server) directive sets the number of consecutive unsuccessful attempts to communicate with the server that should happen during [fail_timeout](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server). By default, [max_fails](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server) is set to 1. When it is set to 0, health checks are disabled for this server. The [fail_timeout](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server) parameter also defines how long the server will be marked as failed. After `fail_timeout` interval following the server failure, nginx will start to gracefully probe the server with the live client’s requests. If the probes have been successful, the server is marked as a live one.

[max_fails](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server) 指令设置了在[fail_timeout](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server)期间内可以发生的尝试与服务器交流而产生的连续失败次数失败次数。默认[max_fails](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server)设置为1。当其设置为0时，该服务器的health检查就不可用。[fail_timeout](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server)参数定义了服务器被标记为failed的时间。过`fail_timeout` 间隔之后是服务器失效，nginx会使用活动客户端请求开启服务器探测。如果探测成功，该服务器会被标记为活动服务器。


##      Further reading

In addition, there are more directives and parameters that control server load balancing in nginx, e.g. [proxy_next_upstream](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream), [backup](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server), [down](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server), and [keepalive](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive). For more information please check our [reference documentation](http://nginx.org/en/docs/).

另外，在nginx中有更多指令及参数可以控制服务器负载平衡，例如：[proxy_next_upstream](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream), [backup](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server), [down](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server), and [keepalive](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive)。更多详情参见[reference documentation](http://nginx.org/en/docs/)。

Last but not least, [application load balancing](https://www.nginx.com/products/nginx/load-balancing/), [application health checks](https://www.nginx.com/products/nginx/load-balancing/#health-checks), [activity monitoring](https://www.nginx.com/products/nginx/live-activity-monitoring/) and [on-the-fly reconfiguration](https://www.nginx.com/products/nginx/load-balancing/#load-balancing-api) of server groups are available as part of our paid NGINX Plus subscriptions.

最后，在我们的付费版本NGINX Plus中，服务器群的[application load balancing](https://www.nginx.com/products/nginx/load-balancing/), [application health checks](https://www.nginx.com/products/nginx/load-balancing/#health-checks), [activity monitoring](https://www.nginx.com/products/nginx/live-activity-monitoring/) and [on-the-fly reconfiguration](https://www.nginx.com/products/nginx/load-balancing/#load-balancing-api) 是可用的。

The following articles describe load balancing with NGINX Plus in more detail:

下列信息介绍了NGINX Plus中的负载平衡：

[Load Balancing with NGINX and NGINX Plus](https://www.nginx.com/blog/load-balancing-with-nginx-plus/?_ga=2.76380181.1294588418.1529202992-2133165853.1528718203)
[Load Balancing with NGINX and NGINX Plus part 2](https://www.nginx.com/blog/load-balancing-with-nginx-plus-part2/?_ga=2.76380181.1294588418.1529202992-2133165853.1528718203)  

[返回](000.Content.md)