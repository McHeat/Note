# 12. Metrics: Spectator, Servo, and Atlas #

Spectator/Servo和Atlas一起使用时，在平台上会提供一个近实时操作（real-time operational）。

Spectator 以及Servo是Netflix’s metrics collection libraries。 Atlas 是 Netflix metrics backend 来处理多维时间序列数据（dimensional time series data）。

Servo为Netflix提供服务很多年了，并且仍然可用。但是由于Spectator，Servo已经逐渐被淘汰，Spectator只设计用来与Java 8一起工作。 Spring Cloud Netflix为这两个都提供支持，但是基于 Java 8的程序最好使用Spectator。

## 12.1 Dimensional vs. Hierarchical Metrics ##
Spring Boot Actuator metrics是分等级的（hierarchical） 并且metrics只是根据那么来进行区分。这些names经常依据命名规则（naming convention），在名字中嵌入由句点分隔的key/value attribute pairs (dimensions)。将下列metrics作为两个endpoints, root and star-star:
{
    "counter.status.200.root": 20,
    "counter.status.400.root": 3,
    "counter.status.200.star-star": 5,
}

第一个metric为对单位时间内对root endpoint的成功请求给出一个标准化计量。但是如果系统具有20各 endpoints，而你想要获取对所有endpoints的成功请求量该怎么办呢？一些hierarchical metrics backends允许你明确一个wild card，例如`counter.status.200.*`，来读取所有 20 个metrics并合计结果。要不然你可以提供一个`HandlerInterceptorAdapter`  ，例如`counter.status.200.all`为所有的successful requests来拦截和记录一个 metric而不用在乎endpoint，但是这种情况你需要编写20+1个不同的metrics。类似的，在服务器中如果你想要为所有的endpoints获取总的successful requests数，可以明确一个 wild card，例如`counter.status.2*.*`。
即使有wildcarding支持hierarchical metrics backend，naming consistency也可以不同。 特别是name string中tags的位置可以伴随时间推移（slip with time）破坏queries。例如，假设HTTP method下我们给上述的hierarchical metrics 添加了额外dimension。那么`counter.status.200.root` 变成了 `counter.status.200.method.get.root`,等等。我们的 `counter.status.200.*` 突然就不再具有相同的语义。甚至， 如果新的dimension不是同一适用于代码库（codebase）， certain queries可能就不能实现。这很快就会失去控制。
Netflix metrics被tagged (a.k.a. dimensional)。每个metric具有一个name但是这单个命名的 metric可以包含多元统计（multiple statistics），并且'tag' key/value pairs允许更大的查询灵活性（querying flexibility）。事实上，statistics本身就记录在特殊的tag中。
使用Netflix Servo或Spectator进行记录，root endpoint的计时器每个status code 包含了4个 statistics， 这里count statistic等于Spring Boot Actuator’s counter。如果到目前为止我们已经遇到HTTP 200和400，将会有8个可用数据点：
{
    "root(status=200,stastic=count)": 20,
    "root(status=200,stastic=max)": 0.7265630630000001,
    "root(status=200,stastic=totalOfSquares)": 0.04759702862580789,
    "root(status=200,stastic=totalTime)": 0.2093076914666667,
    "root(status=400,stastic=count)": 1,
    "root(status=400,stastic=max)": 0,
    "root(status=400,stastic=totalOfSquares)": 0,
    "root(status=400,stastic=totalTime)": 0,
}

## 12.2 Default Metrics Collection ##

无须任何额外的dependencies或配置，基于Spring Cloud的service 将会自动配置一个 Servo `MonitorRegistry`并开始收集每个Spring MVC request的metrics。默认一个名字为`rest`的 Servo timer将会为每个MVC request 而被记录下来，MVC request被如下tagged：


1. HTTP method
2. HTTP status (e.g. 200, 400, 500)
3. URI ( 如果URI为空为 "root"), sanitized for Atlas
4. The exception class name, 如果request handler抛出异常
5. The caller, 如果一个request header使用key matching，使用`netflix.metrics.rest.callerHeader`设置request。`netflix.metrics.rest.callerHeader`没有默认关键字。如果想要收集caller信息，需要将其添加到你的程序properties中。
设置`netflix.metrics.rest.metricName` property来改变来自于`rest`的metric的name到你提供的name。

如果Spring AOP可用，并且`org.aspectj:aspectjweaver` 出现在 runtime classpath，Spring Cloud也将会对每个RestTemplate做出的client call采集metrics。具有restclient的name的一个Servo timer将会为每个MVC request而被记录下来，这些MVC request被如下tagged：

1. HTTP method
2. HTTP status (e.g. 200, 400, 500), "CLIENT_ERROR" 如果响应返回为null, 或"IO_ERROR" 如果一个`IOException`在执行`RestTemplate `method时发生
3. URI, sanitized for Atlas
4. Client name
[Warning]
在`RestTemplate`中避免使用硬编码的url parameters。当 When targeting dynamic endpoints 使用URL variables这会避免潜在的"GC Overhead Limit Reached" 问题 ，在这问题里 `ServoMonitorCache `将每个url看做一个唯一的关键字。

    // recommended
    String orderid = "1";
    restTemplate.getForObject("http://testclient/orders/{orderid}", String.class, orderid)

    // avoid
    restTemplate.getForObject("http://testclient/orders/1", String.class)

## 12.3 Metrics Collection: Spectator ##
为使Spectator metrics有效, include a dependency on `spring-boot-starter-spectator`:

    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-netflix-spectator</artifactId>
    </dependency>
在Spectator parlance中，a meter是一个named、 typed并且tagged配置，并且一个metric 代表了在 一个时间点（point in time）中给与的meter值。 Spectator meters由 registry创建和控制，在当前这个具有多种不同的实现。Spectator提供4个meter types: counter, timer, gauge, and distribution summary.

Spring Cloud Spectator 为你集成配置一个可插入的`com.netflix.spectator.api.Registry` instance。特别的，还配置了一个`ServoRegistry` instance以便统一REST metrics并在单独的Servo API下导出metrics到Atlas backend。实际上这就意味着你的代码可以使用混合了Servo monitors和Spectator meters的方式，这两个都已经被Spring Boot Actuator MetricReader instances收购，并且两个都会被运往Atlas backend.

### 12.3.1 Spectator Counter ###

计数器counter用来测量一些事件发生的比率

    // create a counter with a name and a set of tags
    Counter counter = registry.counter("counterName", "tagKey1", "tagValue1", ...);
    counter.increment(); // increment when an event occurs
    counter.increment(10); // increment by a discrete amount
该counter记录了单个time-normalized statistic.

### 12.3.2 Spectator Timer ###

一个timer用来测量事件发生的时间长度。 Spring Cloud自动为Spring MVC requests以及有条件的`RestTemplate` requests记录timers，以后可用来为与request有关的metrics（如latency）创建dashboards:

Figure 12.1. Request Latency
![](https://raw.githubusercontent.com/spring-cloud/spring-cloud-netflix/1.4.x/docs/src/main/asciidoc/images/RequestLatency.png)
RequestLatency

    // create a timer with a name and a set of tags
    Timer timer = registry.timer("timerName", "tagKey1", "tagValue1", ...);
    
    // execute an operation and time it at the same time
    T result = timer.record(() -> fooReturnsT());
    
    // alternatively, if you must manually record the time
    Long start = System.nanoTime();
    T result = fooReturnsT();
    timer.record(System.nanoTime() - start, TimeUnit.NANOSECONDS);

该timer同时记录4 statistics: count, max, totalOfSquares, and totalTime。
count statistic总是与counter提供的单一归一化值（single normalized value）相符，如果你在每次记录一个timing时called一次 `increment()`，  count就不必要并且对每个单次操作时间也是分开的 （time separately for a single operation）。

对于长时间运行的操作[long running operations](https://github.com/Netflix/spectator/wiki#longtasktimer), Spectator提供一个特殊的`LongTaskTimer`。

### 12.3.3 Spectator Gauge ###

Gauges用于决定一些当前值，例如：队列的大小（size of a queue）或在运行state下threads的数量。因为gauges是取样的，它们不提供关于在两个取样samples之间的波动信息。

gauge的一般用法包括在初始化ID时登记gauge，被sampled对象的reference，以及基于该对象获取或计算数值的函数（function to get or compute a numeric value）。reference to the object是分别传输的并且Spectator registry会给object保留一个weak referenc。如果该object是垃圾回收（garbage collected），那么Spectator将会自动drop the registration。在Spectator’s文档中查阅[the note](https://github.com/Netflix/spectator/wiki#using-lambda)，介绍了如果API被滥用而引起的潜在的内存泄漏（potential memory leaks）。

    // the registry will automatically sample this gauge periodically
    registry.gauge("gaugeName", pool, Pool::numberOfRunningThreads);
    
    // manually sample a value in code at periodic intervals -- last resort!
    registry.gauge("gaugeName", Arrays.asList("tagKey1", "tagValue1", ...), 1000);
### 12.3.4 Spectator Distribution Summaries ###

distribution summary用来追踪事件分布（distribution of events）。它与timer类似，但是对distribution summary更普遍化的是size并非一个时间段。例如，distribution summary可以被用于测量触及服务器的请求的payload sizes。

    // the registry will automatically sample this gauge periodically
    DistributionSummary ds = registry.distributionSummary("dsName", "tagKey1", "tagValue1", ...);
    ds.record(request.sizeInBytes());

## 12.4 Metrics Collection: Servo ##
[Warning]
如果你的代码是由Java 8编译的，请使用Spectator而不是Servo，因为从长远来看Spectator将来注定会完全代替Servo。

在Servo语法中， 一个monitor是一个named、typed以及tagged configuration 和metric，该metic代表在某个时间点上给与的monitor的值。Servo monitors 逻辑上等于Spectator meters。Servo monitors通过一个`MonitorRegistry`来创建与控制。尽管有上述警告， 相较于Spectator的meters，Servo有一个更广泛的monitor options队列（array）。

Spring Cloud集成配置了一个可插入的`com.netflix.servo.MonitorRegistry` instance。一旦你在Servo中创建了适当的Monitor type，数据记录的的过程与Spectator相似。

### 12.4.1 Creating Servo Monitors ###

如果你使用Spring Cloud提供的Servo `MonitorRegistry` instance (特别的， `DefaultMonitorRegistry`instance)， Servo为检索retrieving counters和timers提供了convenience classes。这些convenience classes确保对于每个单一的name and tags组合只有一个`Monitor`被注册。

在Servo中手动创建Monitor type，尤其是对于convenience methods不提供的exotic monitor types ，通过提供`MonitorConfig` instance来实例化合适的type：

    MonitorConfig config = MonitorConfig.builder("timerName").withTag("tagKey1", "tagValue1").build();
    
    // somewhere we should cache this Monitor by MonitorConfig
    Timer timer = new BasicTimer(config);
    monitorRegistry.register(timer);

### 12.5 Metrics Backend: Atlas ###

Atlas是通过Netflix进行开发，为near real-time operational insight管理多维time series data 。Atlas的突出特点是in-memory data storage，可以使其快速的收集与报告大量的metrics。

Atlas智能捕捉（operational intelligence）。然而business intelligence是进行数据收集来分析变化趋势（trends over time），operational intelligence提供当前系统内情况的实时图像。

Spring Cloud提供了一个`spring-cloud-starter-netflix-atlas`，它具有所有你需要的dependencies。然后只需要使用`@EnableAtlas`来注解Spring Boot程序，并使用`netflix.atlas.uri` property为你运行的Atlas server提供location。

### 12.5.1 Global tags ###

Spring Cloud使你能够给每个metric添加tags发送到Atlas backend。Global tags可以通过application name、environment、 region等来区分metrics。

每个bean执行`AtlasTagProvider`将有助于global tag list:

@Bean
AtlasTagProvider atlasCommonTags(
    @Value("${spring.application.name}") String appName) {
  return () -> Collections.singletonMap("app", appName);
}

### 12.5.2 Using Atlas ###

To bootstrap a in-memory standalone Atlas instance:（引导内存中独立的Atlas实例）

    $ curl -LO https://github.com/Netflix/atlas/releases/download/v1.4.2/atlas-1.4.2-standalone.jar
    $ java -jar atlas-1.4.2-standalone.jar
[Tip]
Atlas standalone node运行在一个r3.2xlarge (61GB RAM)，可以为一个给定的六小时窗口(a given 6 hour window)每分钟处理大致2 million metrics。
Once running and you have collected a handful of metrics, verify that your setup is correct by listing tags on the Atlas server:

    $ curl http://ATLAS/api/v1/tags
[Tip]
在执行了几个针对你的service的请求之后，通过在你的浏览器中黏贴以下网址：http://ATLAS/api/v1/graph?q=name,rest,:eq,:avg你就可以收集一些关于每个请求的请求延时request latency 的非常基本的信息。
Atlas wiki包含了多种情况下的[compilation of sample queries](Home · Netflix/atlas Wiki · GitHub  https://github.com/Netflix/atlas/wiki)。

在使用[double exponential smoothing](https://github.com/Netflix/atlas/wiki/DES)来生成动态报警阈值（dynamic alert thresholds）时确保检查[alerting philosophy](https://github.com/Netflix/atlas/wiki/Alerting-Philosophy)以及docs。

## 12.6 Retrying Failed Requests ##
Spring Cloud Netflix提供多种方式来进行HTTP requests。可以使用load balanced `RestTemplate`、 Ribbon或Feign。无论你选择怎样进行HTTP requests，总是有可能会请求失败 。当 request fails你可能希望该request可以自动重试。当使用Sping Cloud Netflix来进行这项工作时需要include [Spring Retry](https://github.com/spring-projects/spring-retry)在你的application’s classpath中。当Spring Retry是目前的load balanced `RestTemplates` ，Feign以及Zuul会自动重试任何失败的请求（假设你的配置允许这样做）。

### 12.6.1 BackOff Policies ###
当retrying requests时默认没有backoff policy被使用。如果你想要配置一个backoff policy，需要你创建一个类型为`LoadBalancedBackOffPolicyFactory`的bean，这会被用于为一个给定的service 创建一个`BackOffPolicy`。

@Configuration
public class MyConfiguration {
    @Bean
    LoadBalancedBackOffPolicyFactory backOffPolciyFactory() {
        return new LoadBalancedBackOffPolicyFactory() {
            @Override
            public BackOffPolicy createBackOffPolicy(String service) {
                return new ExponentialBackOffPolicy();
            }
        };
    }
}

### 12.6.2 Configuration ###

任何时候的Ribbon是使用Spring Retry的，你可以通过配置特定的某些Ribbon properties来控制retry 功能。你可以使用的properties是`client.ribbon.MaxAutoRetries`,和`client.ribbon.MaxAutoRetriesNextServer`以及`client.ribbon.OkToRetryOnAllOperations`。 有关properties的描述请参阅 [Ribbon documentation](https://github.com/Netflix/ribbon/wiki/Getting-Started#the-properties-file-sample-clientproperties) 。

[Warning]
授权 `client.ribbon.OkToRetryOnAllOperations` 使文件包含retring POST requests，由于 request’s body的buffering会影响server’s resources。
另外，在response中当特定的status代码被返回时你可能想要retry requests。使用property `clientName.ribbon.retryableStatusCodes`你可以列出想要让Ribbon client重试的response codes，例如：

clientName:
  ribbon:
    retryableStatusCodes: 404,502

也可以创建一个`LoadBalancedRetryPolicy`类型的并执行`retryableStatusCode` method来依据status code决定你是否想要retry a request。

### 12.6.3 Zuul ###

通过设置`zuul.retryable`为`false`你可以关闭Zuul的 retry功能。也可以使通过设置`zuul.routes.routename.retryable` 为 `false`来禁用在route by route basis中的retry功能